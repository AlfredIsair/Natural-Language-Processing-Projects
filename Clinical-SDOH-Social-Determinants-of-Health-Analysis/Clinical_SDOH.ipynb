{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXeF4fdZkV8OXzkingocpt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlfredIsair/Clinical-SDOH-Social-Determinants-of-Health-Analysis/blob/main/Clinical_SDOH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Colab Setup**"
      ],
      "metadata": {
        "id": "29ovgoFJjfvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IpqFI8c_jDEU"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Oab5eCJejFjb",
        "outputId": "f7c45314-4e85-49e1-b8d0-f9817aa91d09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Upload your John Snow Labs License using the button below\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70b1eacc-4f8a-49b2-8dfb-397df81bac7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70b1eacc-4f8a-49b2-8dfb-397df81bac7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_spark_ocr_8539.json to spark_nlp_for_healthcare_spark_ocr_8539 (1).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical, visual\n",
        "\n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfQ5ly3kjFmD",
        "outputId": "ef9527d2-c1d3-492f-cb1c-7f4194705b7d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8539.json\n",
            "👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8539.json\n",
            "👌 JSL-Home is up to date! \n",
            "👌 Everything is already installed, no changes made\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical, visual\n",
        "import pandas as pd\n",
        "\n",
        "# Automatically load license data and start a session with all jars user has access to\n",
        "spark = nlp.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_D1c3eijFoi",
        "outputId": "7afd2351-41ea-4b19-f0ed-9915cebd00e7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session already created, some configs may not take.\n",
            "👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8539.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql as SQL\n",
        "from pyspark import keyword_only\n",
        "from pyspark.sql.types import StringType"
      ],
      "metadata": {
        "id": "ems4CIaqjFs6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Pipeline"
      ],
      "metadata": {
        "id": "PFsnlQd5jlWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline is designed to process clinical text, identify sentences, tokenize them, generate clinical word embeddings, perform Named Entity Recognition for Social Determinants of Health, and convert the NER results into chunks for further analysis. It can be used to extract valuable information related to SDOH from clinical documents."
      ],
      "metadata": {
        "id": "br5qmhKRjsUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"en\")\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"sentence\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "ner_model = medical.NerModel.pretrained(\"ner_sdoh\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = medical.NerConverterInternal()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "sdoh_pipeline = nlp.Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    clinical_embeddings,\n",
        "    ner_model,\n",
        "    ner_converter\n",
        "    ])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pSq8CPyjFvs",
        "outputId": "89e7e78c-d94e-413b-8240-bf3cf28d8d71"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_sdoh download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "                \"Smith is a 55 years old, divorced Mexcian American woman with financial problems. She speaks spanish. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. She has a son student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reprots having her catholic faith as a means of support as well.  She has long history of etoh abuse, beginning in her teens. She reports she has been drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI back in April and was due to be in court this week.\"\n",
        "                ]\n",
        ""
      ],
      "metadata": {
        "id": "MbLZc-9PjLoL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #creating a Spark DataFrame\n",
        "data = spark.createDataFrame(sample_texts, StringType()).toDF(\"text\")"
      ],
      "metadata": {
        "id": "lLWQSXoDjLq6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sdoh_pipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "qQVPsq6DjLti"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".fit(data): This part fits (trains) the pipeline on the input data (data DataFrame). During the fitting process, the pipeline learns from the data and configures its components accordingly.\n",
        "\n",
        ".transform(data): This part applies the fitted pipeline to the input data, transforming it into a new DataFrame (result). The transformation involves processing the clinical text through the various stages of the pipeline, and the result is a DataFrame containing the original columns and additional columns generated by the pipeline (e.g., NER results, embeddings)."
      ],
      "metadata": {
        "id": "0r3OARqzs5CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets provides a tabular view of the NER chunks and their associated labels.\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,\n",
        "                                     result.ner_chunk.metadata)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(30, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmff-ZiIjLvr",
        "outputId": "cc73d672-4456-417b-8c4d-5688f94232d4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-------------------+\n",
            "|chunk             |ner_label          |\n",
            "+------------------+-------------------+\n",
            "|55 years old      |Age                |\n",
            "|divorced          |Marital_Status     |\n",
            "|Mexcian American  |Race_Ethnicity     |\n",
            "|woman             |Gender             |\n",
            "|financial problems|Financial_Status   |\n",
            "|She               |Gender             |\n",
            "|spanish           |Language           |\n",
            "|She               |Gender             |\n",
            "|apartment         |Housing            |\n",
            "|She               |Gender             |\n",
            "|diabetes          |Other_Disease      |\n",
            "|hospitalizations  |Other_SDoH_Keywords|\n",
            "|cleaning assistant|Employment         |\n",
            "|health insurance  |Insurance_Status   |\n",
            "|She               |Gender             |\n",
            "|son               |Family_Member      |\n",
            "|student           |Education          |\n",
            "|college           |Education          |\n",
            "|depression        |Mental_Health      |\n",
            "|She               |Gender             |\n",
            "|she               |Gender             |\n",
            "|rehab             |Access_To_Care     |\n",
            "|her               |Gender             |\n",
            "|catholic faith    |Spiritual_Beliefs  |\n",
            "|support           |Social_Support     |\n",
            "|She               |Gender             |\n",
            "|etoh abuse        |Alcohol            |\n",
            "|her               |Gender             |\n",
            "|teens             |Age                |\n",
            "|She               |Gender             |\n",
            "+------------------+-------------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = nlp.viz.NerVisualizer()\n",
        "\n",
        "for i in range(len(sample_texts)):\n",
        "    visualizer.display(\n",
        "        result = result.collect()[i],\n",
        "        label_col = 'ner_chunk',\n",
        "        document_col = 'document'\n",
        "    )\n",
        "    print(\"\\n\"*2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "4JNyVo6ZjbSi",
        "outputId": "e509bd21-f470-4e57-fc35-e8377cf38dce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Smith is a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">55 years old </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #78438F\"><span class=\"spark-nlp-display-entity-name\">divorced </span><span class=\"spark-nlp-display-entity-type\">Marital_Status</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B2059A\"><span class=\"spark-nlp-display-entity-name\">Mexcian American </span><span class=\"spark-nlp-display-entity-type\">Race_Ethnicity</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">woman </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1627A2\"><span class=\"spark-nlp-display-entity-name\">financial problems </span><span class=\"spark-nlp-display-entity-type\">Financial_Status</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> speaks </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7F976A\"><span class=\"spark-nlp-display-entity-name\">spanish </span><span class=\"spark-nlp-display-entity-type\">Language</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> lives in an </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #887F1B\"><span class=\"spark-nlp-display-entity-name\">apartment </span><span class=\"spark-nlp-display-entity-type\">Housing</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> has been struggling with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9A333D\"><span class=\"spark-nlp-display-entity-name\">diabetes </span><span class=\"spark-nlp-display-entity-type\">Other_Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the past 10 years and has recently been experiencing frequent </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #11B5B7\"><span class=\"spark-nlp-display-entity-name\">hospitalizations </span><span class=\"spark-nlp-display-entity-type\">Other_SDoH_Keywords</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> due to uncontrolled blood sugar levels. Smith works as a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #371090\"><span class=\"spark-nlp-display-entity-name\">cleaning assistant </span><span class=\"spark-nlp-display-entity-type\">Employment</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and does not have access to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #C888B9\"><span class=\"spark-nlp-display-entity-name\">health insurance </span><span class=\"spark-nlp-display-entity-type\">Insurance_Status</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or paid sick leave. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> has a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #082D2C\"><span class=\"spark-nlp-display-entity-name\">son </span><span class=\"spark-nlp-display-entity-type\">Family_Member</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #088D12\"><span class=\"spark-nlp-display-entity-name\">student </span><span class=\"spark-nlp-display-entity-type\">Education</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> at </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #088D12\"><span class=\"spark-nlp-display-entity-name\">college </span><span class=\"spark-nlp-display-entity-type\">Education</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Pt with likely long-standing </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A08DAF\"><span class=\"spark-nlp-display-entity-name\">depression </span><span class=\"spark-nlp-display-entity-type\">Mental_Health</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is aware </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">she </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> needs </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BD5859\"><span class=\"spark-nlp-display-entity-name\">rehab </span><span class=\"spark-nlp-display-entity-type\">Access_To_Care</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Pt reprots having </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">her </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A84A3F\"><span class=\"spark-nlp-display-entity-name\">catholic faith </span><span class=\"spark-nlp-display-entity-type\">Spiritual_Beliefs</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> as a means of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4A9F7D\"><span class=\"spark-nlp-display-entity-name\">support </span><span class=\"spark-nlp-display-entity-type\">Social_Support</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> as well.  </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> has long history of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92050D\"><span class=\"spark-nlp-display-entity-name\">etoh abuse </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, beginning in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">her </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">teens </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> reports </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">she </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> has been </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92050D\"><span class=\"spark-nlp-display-entity-name\">drinker </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1B944A\"><span class=\"spark-nlp-display-entity-name\">30 years </span><span class=\"spark-nlp-display-entity-type\">Substance_Duration</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, most recently </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92050D\"><span class=\"spark-nlp-display-entity-name\">drinking </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92050D\"><span class=\"spark-nlp-display-entity-name\">beer </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #98566F\"><span class=\"spark-nlp-display-entity-name\">daily </span><span class=\"spark-nlp-display-entity-type\">Substance_Frequency</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1E2A58\"><span class=\"spark-nlp-display-entity-name\">smokes </span><span class=\"spark-nlp-display-entity-type\">Smoking</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #688285\"><span class=\"spark-nlp-display-entity-name\">a pack </span><span class=\"spark-nlp-display-entity-type\">Substance_Quantity</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1E2A58\"><span class=\"spark-nlp-display-entity-name\">cigarettes </span><span class=\"spark-nlp-display-entity-type\">Smoking</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #98566F\"><span class=\"spark-nlp-display-entity-name\">a day </span><span class=\"spark-nlp-display-entity-type\">Substance_Frequency</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">She </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> had </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #12840A\"><span class=\"spark-nlp-display-entity-name\">DUI </span><span class=\"spark-nlp-display-entity-type\">Legal_Issues</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> back in April and was due to be in court this week.</span></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These SDOH elements provide a comprehensive view of the patient's social and environmental context, contributing to a holistic understanding of health and potential healthcare needs.\n",
        "\n",
        "Recognizing and addressing SDOH is essential for healthcare practitioners aiming to provide patient-centered care. By delving into these determinants, healthcare professionals can tailor interventions, enhance patient engagement, and create more effective and equitable healthcare strategies. This comprehensive understanding allows for a holistic approach, acknowledging that health outcomes are influenced by a complex interplay of social, economic, and environmental factors.\n",
        "\n"
      ],
      "metadata": {
        "id": "9S8hBiz5qimp"
      }
    }
  ]
}